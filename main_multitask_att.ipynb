{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Boundary detection with NER features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "from tqdm import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_newline_to_EOS(file_r, file_w):\n",
    "    with open(file_w, 'w', encoding=\"UTF-8\") as fw:\n",
    "        with open(file_r, 'r', encoding=\"UTF-8\") as fr:\n",
    "            while True:\n",
    "                line = fr.readline()\n",
    "                if not line: break\n",
    "                if line == '\\n':\n",
    "                    fw.write(\"<EOS>\\t<EOS>\\t<EOS>\\t<EOS>\\n\")\n",
    "                else:\n",
    "                    fw.write(line)\n",
    "                    \n",
    "def set_sentence_num(df): \n",
    "\n",
    "    sent_num = 0\n",
    "    df['sent_num'] = sent_num\n",
    "    for idx in range(len(df)):\n",
    "        df['sent_num'][idx] = sent_num\n",
    "        #if df[0][idx]=='.' and df[1][idx]==\"SENT\":\n",
    "        if df[0][idx]=='<EOS>' and df[1][idx]==\"<EOS>\":\n",
    "            sent_num +=1\n",
    "    df.head()\n",
    "    df = df[df[0] != \"<EOS>\"] #get rid of the \"<EOS>\" toekns\n",
    "    print(sent_num)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "train_file = './data/test.tsv'\n",
    "test_file = './data/test.tsv'\n",
    "train_EOS_file = './data/train_EOS.tsv'\n",
    "test_EOS_file = './data/test_EOS.tsv'\n",
    "#test_file = './data_v1/europarl-sbd-eval.tsv'\n",
    "\n",
    "set_newline_to_EOS(train_file, train_EOS_file)\n",
    "set_newline_to_EOS(test_file, test_EOS_file)\n",
    "train_file = train_EOS_file\n",
    "test_file = test_EOS_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La</td>\n",
       "      <td>DET:ART</td>\n",
       "      <td>O</td>\n",
       "      <td>B-SENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cérémonie</td>\n",
       "      <td>NOM</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aura</td>\n",
       "      <td>VER:futu</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lieu</td>\n",
       "      <td>NOM</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>le</td>\n",
       "      <td>DET:ART</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1  2       3\n",
       "0         La   DET:ART  O  B-SENT\n",
       "1  cérémonie       NOM  O       O\n",
       "2       aura  VER:futu  O       O\n",
       "3       lieu       NOM  O       O\n",
       "4         le   DET:ART  O       O"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_file, delimiter='\\t', engine='python', encoding='UTF-8', error_bad_lines=False, header=None, quoting=csv.QUOTE_NONE)\n",
    "train_df.head()\n",
    "test_df = pd.read_csv(test_file, delimiter='\\t', engine='python', encoding='UTF-8', error_bad_lines=False, header=None, quoting=csv.QUOTE_NONE)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2593\n",
      "2593\n"
     ]
    }
   ],
   "source": [
    "train_df = set_sentence_num(train_df)\n",
    "test_df = set_sentence_num(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df['sent_num'] < 100000]\n",
    "test_df = test_df[test_df['sent_num'] < 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cérémonie aura lieu le lundi 28 décembre 2009 , à 10h30 , au crématorium de Tours-Sud , à Esvres-sur-Indre , pour lui rendre hommage .\n"
     ]
    }
   ],
   "source": [
    "sentence = train_df[train_df['sent_num']==0]\n",
    "token_list =  ' '.join([token for token in sentence[0]])\n",
    "print(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FSBDataset():\n",
    "    def __init__(self, data, tokenizer, max_length):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.idxtob = {'B-SENT': 1}\n",
    "        self.idxtoPOS = {'DET:ART': 0,'NAM': 1,'KON': 2,'PUN': 3,'DET:POS': 4,'NOM': 5,'VER:pres': 6,'PRP': 7,'PRO:PER': 8,'VER:infi': 9,'PRP:det': 10,'VER:simp': 11,'VER:pper': 12,'NUM': 13,'SENT': 14,'ABR': 15,'VER:futu': 16,'PRO:DEM': 17,'ADJ': 18,\n",
    " 'PRO:REL': 19,'PRO:IND': 20,'ADV': 21,'SYM': 22,'PUN:cit': 23,'VER:impf': 24,'VER:subp': 25,'VER:subi': 26,'VER:ppre': 27,'VER:cond': 28,'PRO:POS': 29,'VER:impe': 30}\n",
    "        self.idxtoNER = {'I-LOC': 0, 'I-PER': 1, 'O': 2, 'I-ORG': 3}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data['sent_num'].max()\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        \n",
    "        sentence = self.data[self.data['sent_num']==item]\n",
    "        token_list =  [token for token in sentence[0]]\n",
    "        sbd_list =  [target for target in sentence[3]]\n",
    "        pos_list =  [target for target in sentence[1]]\n",
    "        ner_list =  [target for target in sentence[2]]\n",
    "        \n",
    "        #target_ids_list =  [1 if token==\"B-SENT\" else 0 for token in sentence[3]]\n",
    "        #pos_ids = [self.idxtoPOS.get(pos) for pos in sentence[1]]\n",
    "        #ner_ids = [self.idxtoNER.get(ner) for ner in sentence[2]]\n",
    "        \n",
    "        encoded = self.tokenizer.encode_plus(' '.join(token_list),\n",
    "                                            None,\n",
    "                                            add_special_tokens=True,\n",
    "                                            max_length=self.max_length,\n",
    "                                            truncation=True,\n",
    "                                            padding='max_length')\n",
    "        \n",
    "        ids = encoded['input_ids']\n",
    "        mask = encoded['attention_mask']\n",
    "        \n",
    "        bpe_head_mask = [0]; sbd_ids = [-1]; pos_ids = [-1]; ner_ids = [-1] # --> CLS token\n",
    "        \n",
    "        for word, sbd, pos, ner in zip(token_list, sbd_list, pos_list, ner_list):\n",
    "            bpe_len = len(self.tokenizer.tokenize(word))\n",
    "            head_mask = [1] + [0]*(bpe_len-1)\n",
    "            bpe_head_mask.extend(head_mask)\n",
    "            \n",
    "            sbd_mask = [self.idxtob.get(sbd,0)] + [-1]*(bpe_len-1)\n",
    "            sbd_ids.extend(sbd_mask)\n",
    "            pos_mask = [self.idxtoPOS.get(pos,0)] + [-1]*(bpe_len-1)\n",
    "            pos_ids.extend(pos_mask)\n",
    "            ner_mask = [self.idxtoNER.get(ner,0)] + [-1]*(bpe_len-1)\n",
    "            ner_ids.extend(ner_mask)\n",
    "            #print(\"head_mask\", head_mask)\n",
    "        \n",
    "        bpe_head_mask.append(0)\n",
    "        bpe_head_mask.extend([0] * (self.max_length - len(bpe_head_mask)))\n",
    "        \n",
    "        sbd_ids.append(-1) # --> END token\n",
    "        sbd_ids.extend([-1] * (self.max_length - len(sbd_ids))) ## --> padding by max_len\n",
    "        pos_ids.append(-1) # --> END token\n",
    "        pos_ids.extend([-1] * (self.max_length - len(pos_ids))) ## --> padding by max_len\n",
    "        ner_ids.append(-1) # --> END token\n",
    "        ner_ids.extend([-1] * (self.max_length - len(ner_ids))) ## --> padding by max_len\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'bpe_head_mask': torch.tensor(bpe_head_mask, dtype=torch.long),\n",
    "            'sbd_ids': torch.tensor(sbd_ids, dtype=torch.long),\n",
    "            'pos_ids': torch.tensor(pos_ids, dtype=torch.long),\n",
    "            'ner_ids': torch.tensor(ner_ids, dtype=torch.long)\n",
    "        }\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XLMRobertaBaseline(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XLMRobertaBaseline, self).__init__()\n",
    "        \n",
    "        self.bert = transformers.XLMRobertaModel.from_pretrained('xlm-roberta-base')\n",
    "        self.dropout = torch.nn.Dropout(0.33)\n",
    "        self.classfier = torch.nn.Linear(768, 2)\n",
    "        \n",
    "        \n",
    "    def forward(self, ids, mask):\n",
    "        \n",
    "        o1, o2 = self.bert(ids, mask)\n",
    "        out = self.dropout(o1)\n",
    "        logits = self.classfier(out)\n",
    "        \n",
    "        return logits\n",
    "        \n",
    "        \n",
    "    \n",
    "class POS(torch.nn.Module):\n",
    "    def __init__(self, num_pos=31):\n",
    "        super(POS, self).__init__()\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(0.33)\n",
    "        self.classfier = torch.nn.Linear(768, num_pos)\n",
    "        \n",
    "    def forward(self, bert_out):\n",
    "        \n",
    "        o1 = bert_out\n",
    "        out = self.dropout(o1)\n",
    "        logits = self.classfier(out)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "    \n",
    "class NER(torch.nn.Module):\n",
    "    def __init__(self, num_ner=4):\n",
    "        super(NER, self).__init__()\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(0.33)\n",
    "        self.classfier = torch.nn.Linear(768, num_ner)\n",
    "        \n",
    "    def forward(self, bert_out):\n",
    "        \n",
    "        o1 = bert_out\n",
    "        out = self.dropout(o1)\n",
    "        logits = self.classfier(out)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "    \n",
    "class SBD(torch.nn.Module):\n",
    "    def __init__(self, input_dim=768, num_sbd=2):\n",
    "        super(SBD, self).__init__()\n",
    "        \n",
    "        self.dropout = torch.nn.Dropout(0.33)\n",
    "        self.classfier = torch.nn.Linear(input_dim, num_sbd)\n",
    "        \n",
    "    def forward(self, bert_out):\n",
    "        \n",
    "        o1 = bert_out\n",
    "        out = self.dropout(o1)\n",
    "        logits = self.classfier(out)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "    \n",
    "class XLMRobertaMultiTask(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XLMRobertaMultiTask, self).__init__()\n",
    "        \n",
    "        num_pos = 31\n",
    "        num_ner = 4\n",
    "        num_sbd = 2\n",
    "        pos_dim = 50\n",
    "        ner_dim = 25\n",
    "        \n",
    "        self.bert = transformers.XLMRobertaModel.from_pretrained('xlm-roberta-base')\n",
    "        \n",
    "        self.pos = POS(num_pos)\n",
    "        self.ner = NER(num_ner)\n",
    "        self.sbd = SBD(num_sbd)\n",
    "        \n",
    "        self.pos_emb = torch.nn.Embedding(num_pos, pos_dim)\n",
    "        self.ner_emb = torch.nn.Embedding(num_ner, ner_dim)\n",
    "        \n",
    "        \n",
    "    def forward(self, ids, mask):\n",
    "        \n",
    "        o1, o2 = self.bert(ids, mask)\n",
    "        out = o1 \n",
    "        \n",
    "        pos_logits = self.pos(out)\n",
    "        ner_logits = self.ner(out)\n",
    "        sbd_logits = self.sbd(out)\n",
    "\n",
    "        \n",
    "        return sbd_logits, pos_logits, ner_logits\n",
    "    \n",
    "    \n",
    "    \n",
    "class XLMRobertaMultiTaskPred(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XLMRobertaMultiTaskPred, self).__init__()\n",
    "        \n",
    "        num_pos = 31\n",
    "        num_ner = 4\n",
    "        num_sbd = 2\n",
    "        pos_dim = 50\n",
    "        ner_dim = 25\n",
    "        \n",
    "        self.bert = transformers.XLMRobertaModel.from_pretrained('xlm-roberta-base')\n",
    "        \n",
    "        self.pos = POS(num_pos)\n",
    "        self.ner = NER(num_ner)\n",
    "        self.sbd = SBD(768+pos_dim+ner_dim, num_sbd)\n",
    "        \n",
    "        self.pos_emb = torch.nn.Embedding(num_pos, pos_dim)\n",
    "        self.ner_emb = torch.nn.Embedding(num_ner, ner_dim)\n",
    "        \n",
    "        \n",
    "    def forward(self, ids, mask):\n",
    "        \n",
    "        o1, o2 = self.bert(ids, mask)\n",
    "        out = o1 #self.dropout(o1)\n",
    "        \n",
    "        #Step1: predict POS tags for the entire toekns\n",
    "        pos_logits = self.pos(out)\n",
    "        ner_logits = self.ner(out)\n",
    "        \n",
    "        pos_idx = torch.argmax(pos_logits, dim=2)\n",
    "        ner_idx = torch.argmax(ner_logits, dim=2)\n",
    "        \n",
    "        pos_emb = self.pos_emb(pos_idx)\n",
    "        ner_emb = self.ner_emb(ner_idx)\n",
    "\n",
    "        concatenated = torch.cat([out, pos_emb, ner_emb], dim=2)\n",
    "        sbd_logits = self.sbd(concatenated)\n",
    "        \n",
    "        return sbd_logits, pos_logits, ner_logits\n",
    "    \n",
    "    \n",
    "    \n",
    "'''\n",
    "class BaseAttention(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseAttention, self).__init__()\n",
    "        \n",
    "\n",
    "        self.query = torch.nn.Linear(768, 200)\n",
    "        self.key = torch.nn.Linear()\n",
    "        \n",
    "        self.attention = BaseAttention()\n",
    "        \n",
    "        \n",
    "    def forward(self, ids, mask):\n",
    "        \n",
    "'''    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class XLMRobertaMultiTaskPredAtt(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(XLMRobertaMultiTaskPredAtt, self).__init__()\n",
    "        \n",
    "        num_pos = 31\n",
    "        num_ner = 4\n",
    "        num_sbd = 2\n",
    "        pos_dim = 50\n",
    "        ner_dim = 25\n",
    "        \n",
    "        self.bert = transformers.XLMRobertaModel.from_pretrained('xlm-roberta-base')\n",
    "        \n",
    "        self.pos = POS(num_pos)\n",
    "        self.ner = NER(num_ner)\n",
    "        self.sbd = SBD(768+pos_dim+ner_dim, num_sbd)\n",
    "        \n",
    "        self.pos_emb = torch.nn.Embedding(num_pos, pos_dim)\n",
    "        self.ner_emb = torch.nn.Embedding(num_ner, ner_dim)\n",
    "        \n",
    "        self.attention = BaseAttention()\n",
    "        \n",
    "        \n",
    "    def forward(self, ids, mask):\n",
    "        \n",
    "        o1, o2 = self.bert(ids, mask)\n",
    "        out = o1 #self.dropout(o1)\n",
    "        \n",
    "        #Step1: predict POS tags for the entire toekns\n",
    "        pos_logits = self.pos(out)\n",
    "        ner_logits = self.ner(out)\n",
    "        \n",
    "        pos_idx = torch.argmax(pos_logits, dim=2)\n",
    "        ner_idx = torch.argmax(ner_logits, dim=2)\n",
    "        \n",
    "        pos_emb = self.pos_emb(pos_idx)\n",
    "        ner_emb = self.ner_emb(ner_idx)\n",
    "        \n",
    "        concatenated = torch.cat([out, pos_emb, ner_emb], dim=2)\n",
    "        sbd_logits = self.sbd(concatenated)\n",
    "        \n",
    "        #att_emb = self.attention(out, pos_emb, ner_emb)\n",
    "        \n",
    "        \n",
    "        return sbd_logits, pos_logits, ner_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 510\n",
    "tokenizer = transformers.XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
    "train_dataset = FSBDataset(train_df, tokenizer, MAX_LEN)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, num_workers=1, batch_size=1)\n",
    "test_dataset = FSBDataset(test_df, tokenizer, MAX_LEN)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, shuffle=False, num_workers=4, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = XLMRobertaBaseline()\n",
    "#model = XLMRobertaMultiTask()\n",
    "model = XLMRobertaMultiTaskPred()\n",
    "model = torch.nn.DataParallel(model)\n",
    "model = model.cuda()\n",
    "optimizer = transformers.AdamW(params=model.parameters(), lr=0.000005)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(total_pred, total_targ):\n",
    "    \n",
    "    p = 0 # (retrived SB and real SB) / retrived SB  # The percentage of (the number of correct predictions) / (the number of predction that system predicts as B-SENT)\n",
    "    r = 0\n",
    "    f1= 0\n",
    "\n",
    "    np_total_pred = np.array(total_pred)\n",
    "    np_total_tag = np.array(total_targ)\n",
    "    \n",
    "    #precision\n",
    "    incidence_nopad = np.where(np_total_tag != -1) ## eliminate paddings\n",
    "    #print(\"incidence_nopad\", incidence_nopad)\n",
    "    \n",
    "    np_total_pred_nopad = np_total_pred[incidence_nopad]\n",
    "    np_total_tag_nopad = np_total_tag[incidence_nopad]\n",
    "    \n",
    "    incidence_nopad_sb = np.where(np_total_pred_nopad == 1)\n",
    "    np_total_pred_nopad_sb = np_total_pred_nopad[incidence_nopad_sb]\n",
    "    np_total_tag_nopad_sb = np_total_tag_nopad[incidence_nopad_sb]\n",
    "    \n",
    "    count_active_tokens_p = len(np_total_pred_nopad_sb)\n",
    "    count_correct_p = np.count_nonzero((np_total_pred_nopad_sb==np_total_tag_nopad_sb) == True)\n",
    "    \n",
    "    print(\"count_correct_p\", count_correct_p)\n",
    "    print(\"count_active_tokens_p\", count_active_tokens_p)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        p = count_correct_p/count_active_tokens_p\n",
    "    except ZeroDivisionError:\n",
    "        p = 0\n",
    "    \n",
    "\n",
    "    print(\"precision:\", p)\n",
    "\n",
    "    \n",
    "    #recall\n",
    "    ids_sb_pred_r = np.where(np_total_tag==1)\n",
    "    np_total_pred_r = np_total_pred[ids_sb_pred_r]\n",
    "    np_total_tag_r = np_total_tag[ids_sb_pred_r]\n",
    "    \n",
    "    count_active_tokens_r = len(np_total_pred_r)\n",
    "    count_correct_r = np.count_nonzero((np_total_pred_r==np_total_tag_r) == True)\n",
    "    \n",
    "    print(\"count_active_tokens_r\", count_active_tokens_r)\n",
    "    print(\"count_correct_r\", count_correct_r)\n",
    "    \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        r = count_correct_r/count_active_tokens_r\n",
    "    except ZeroDivisionError:\n",
    "        r = 0\n",
    "    \n",
    "    print(\"recall:\", r)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        f1 = 2*(p*r) / (p+r)\n",
    "    except ZeroDivisionError:\n",
    "        f1 = 0\n",
    "    \n",
    "\n",
    "    print(\"F1:\", f1)\n",
    "    \n",
    "    \n",
    "    \n",
    "def ner_f1_score(total_pred, total_targ):\n",
    "    \n",
    "    p = 0 # (retrived SB and real SB) / retrived SB  # The percentage of (the number of correct predictions) / (the number of predction that system predicts as B-SENT)\n",
    "    r = 0\n",
    "    f1= 0\n",
    "\n",
    "    np_total_pred = np.array(total_pred)\n",
    "    np_total_tag = np.array(total_targ)\n",
    "    \n",
    "    #precision\n",
    "    incidence_nopad = np.where(np_total_tag != -1) ## eliminate paddings\n",
    "    #print(\"incidence_nopad\", incidence_nopad)\n",
    "    \n",
    "    np_total_pred_nopad = np_total_pred[incidence_nopad]\n",
    "    np_total_tag_nopad = np_total_tag[incidence_nopad]\n",
    "    \n",
    "    incidence_nopad_sb = np.where((np_total_pred_nopad != -1) & (np_total_pred_nopad != 2)) #np.where(np_total_pred_nopad == 1) \n",
    "    np_total_pred_nopad_sb = np_total_pred_nopad[incidence_nopad_sb]\n",
    "    np_total_tag_nopad_sb = np_total_tag_nopad[incidence_nopad_sb]\n",
    "    \n",
    "    count_active_tokens_p = len(np_total_pred_nopad_sb)\n",
    "    count_correct_p = np.count_nonzero((np_total_pred_nopad_sb==np_total_tag_nopad_sb) == True)\n",
    "    \n",
    "    print(\"count_correct_p\", count_correct_p)\n",
    "    print(\"count_active_tokens_p\", count_active_tokens_p)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        p = count_correct_p/count_active_tokens_p\n",
    "    except ZeroDivisionError:\n",
    "        p = 0\n",
    "    \n",
    "\n",
    "    print(\"precision:\", p)\n",
    "\n",
    "    \n",
    "    #recall\n",
    "    ids_sb_pred_r = np.where((np_total_tag != -1) & (np_total_tag != 2)) #np.where(np_total_tag==1)\n",
    "    np_total_pred_r = np_total_pred[ids_sb_pred_r]\n",
    "    np_total_tag_r = np_total_tag[ids_sb_pred_r]\n",
    "    \n",
    "    count_active_tokens_r = len(np_total_pred_r)\n",
    "    count_correct_r = np.count_nonzero((np_total_pred_r==np_total_tag_r) == True)\n",
    "    \n",
    "    print(\"count_active_tokens_r\", count_active_tokens_r)\n",
    "    print(\"count_correct_r\", count_correct_r)\n",
    "    \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        r = count_correct_r/count_active_tokens_r\n",
    "    except ZeroDivisionError:\n",
    "        r = 0\n",
    "    \n",
    "    print(\"recall:\", r)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        f1 = 2*(p*r) / (p+r)\n",
    "    except ZeroDivisionError:\n",
    "        f1 = 0\n",
    "    \n",
    "\n",
    "    print(\"F1:\", f1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop_fn(train_loader, model, optimizer, DEVICE=None, scheduler=None, mode=\"all\"):\n",
    "    model.train()\n",
    "    \n",
    "    sbd_pred = []\n",
    "    sbd_targ = []\n",
    "    sbd_loss = []\n",
    "    \n",
    "    pos_pred = []\n",
    "    pos_targ = []\n",
    "    pos_loss = []\n",
    "    \n",
    "    ner_pred = []\n",
    "    ner_targ = []\n",
    "    ner_loss = []\n",
    "    \n",
    "    for idx, batch in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        sbd_logits, pos_logits, ner_logits = model(batch['ids'].cuda(), batch['mask'].cuda())\n",
    "        \n",
    "        #if mode = \"all\" or \"sbd\":\n",
    "        b,s,l = sbd_logits.size()\n",
    "        s_loss = loss_fn(sbd_logits.view(b*s,l), batch['sbd_ids'].cuda().view(b*s))\n",
    "        sbd_loss.append(s_loss.item())\n",
    "        sbd_pred.extend(torch.argmax(sbd_logits.view(b*s,l), 1).cpu().tolist())\n",
    "        sbd_targ.extend(batch['sbd_ids'].cuda().view(b*s).cpu().tolist())\n",
    "\n",
    "        b,s,l = pos_logits.size()\n",
    "        p_loss = loss_fn(pos_logits.view(b*s,l), batch['pos_ids'].cuda().view(b*s))\n",
    "        pos_loss.append(p_loss.item())\n",
    "        pos_pred.extend(torch.argmax(pos_logits.view(b*s,l), 1).cpu().tolist())\n",
    "        pos_targ.extend(batch['pos_ids'].cuda().view(b*s).cpu().tolist())\n",
    "        \n",
    "        b,s,l = ner_logits.size()\n",
    "        n_loss = loss_fn(ner_logits.view(b*s,l), batch['ner_ids'].cuda().view(b*s))\n",
    "        ner_loss.append(n_loss.item())\n",
    "        ner_pred.extend(torch.argmax(ner_logits.view(b*s,l), 1).cpu().tolist())\n",
    "        ner_targ.extend(batch['ner_ids'].cuda().view(b*s).cpu().tolist())\n",
    "        \n",
    "        loss = s_loss + n_loss# + p_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "            \n",
    "    sbd_count_active_tokens = np.count_nonzero(np.array(sbd_targ) > -1)\n",
    "    sbd_count_correct = np.count_nonzero((np.array(sbd_pred)==np.array(sbd_targ)) == True)\n",
    "    pos_count_active_tokens = np.count_nonzero(np.array(pos_targ) > -1)\n",
    "    pos_count_correct = np.count_nonzero((np.array(pos_pred)==np.array(pos_targ)) == True)\n",
    "    ner_count_active_tokens = np.count_nonzero(np.array(ner_targ) > -1)\n",
    "    ner_count_correct = np.count_nonzero((np.array(ner_pred)==np.array(ner_targ)) == True)\n",
    "    \n",
    "    f1_score(sbd_pred, sbd_targ)\n",
    "    print(\"POS Accuracy:\"+ str(pos_count_correct/pos_count_active_tokens))\n",
    "    print(\"NER Accuracy:\"+ str(ner_count_correct/ner_count_active_tokens))\n",
    "    ner_f1_score(ner_pred, ner_targ)\n",
    "    \n",
    "    #f1_score(total_pred[2:], total_targ[2:])\n",
    "\n",
    "    \n",
    "def dev_loop_fn(dev_loader, model, optimizer, DEVICE=None, scheduler=None):\n",
    "    model.eval()\n",
    "    \n",
    "    sbd_pred = []\n",
    "    sbd_targ = []\n",
    "    sbd_loss = []\n",
    "    sbd_middle_pred = []\n",
    "    sbd_middle_targ = []\n",
    "    \n",
    "    pos_pred = []\n",
    "    pos_targ = []\n",
    "    pos_loss = []\n",
    "    \n",
    "    ner_pred = []\n",
    "    ner_targ = []\n",
    "    ner_loss = []\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in tqdm(enumerate(dev_loader), total=len(dev_loader)):\n",
    "\n",
    "            sbd_logits, pos_logits, ner_logits = model(batch['ids'].cuda(), batch['mask'].cuda())\n",
    "\n",
    "            #if mode = \"all\" or \"sbd\":\n",
    "            b,s,l = sbd_logits.size()\n",
    "            s_loss = loss_fn(sbd_logits.view(b*s,l), batch['sbd_ids'].cuda().view(b*s))\n",
    "            sbd_loss.append(s_loss.item())\n",
    "            sbd_pred.extend(torch.argmax(sbd_logits.view(b*s,l), 1).cpu().tolist())\n",
    "            sbd_targ.extend(batch['sbd_ids'].cuda().view(b*s).cpu().tolist())\n",
    "\n",
    "            b,s,l = pos_logits.size()\n",
    "            p_loss = loss_fn(pos_logits.view(b*s,l), batch['pos_ids'].cuda().view(b*s))\n",
    "            pos_loss.append(p_loss.item())\n",
    "            pos_pred.extend(torch.argmax(pos_logits.view(b*s,l), 1).cpu().tolist())\n",
    "            pos_targ.extend(batch['pos_ids'].cuda().view(b*s).cpu().tolist())\n",
    "\n",
    "            b,s,l = ner_logits.size()\n",
    "            n_loss = loss_fn(ner_logits.view(b*s,l), batch['ner_ids'].cuda().view(b*s))\n",
    "            ner_loss.append(n_loss.item())\n",
    "            ner_pred.extend(torch.argmax(ner_logits.view(b*s,l), 1).cpu().tolist())\n",
    "            ner_targ.extend(batch['ner_ids'].cuda().view(b*s).cpu().tolist())\n",
    "            \n",
    "\n",
    "            sbd_logits_middle = sbd_logits[:,2:,]\n",
    "            b,s,l = sbd_logits_middle.size()\n",
    "            #print(b,s,l)\n",
    "            sbd_middle_pred.extend(torch.argmax(sbd_logits_middle.contiguous().view(b*s,l), 1).cpu().tolist())\n",
    "            sbd_middle_targ.extend(batch['sbd_ids'][:,2:].cuda().contiguous().view(b*s).cpu().tolist())\n",
    "            \n",
    "\n",
    "    sbd_count_active_tokens = np.count_nonzero(np.array(sbd_targ) > -1)\n",
    "    sbd_count_correct = np.count_nonzero((np.array(sbd_pred)==np.array(sbd_targ)) == True)\n",
    "    pos_count_active_tokens = np.count_nonzero(np.array(pos_targ) > -1)\n",
    "    pos_count_correct = np.count_nonzero((np.array(pos_pred)==np.array(pos_targ)) == True)\n",
    "    ner_count_active_tokens = np.count_nonzero(np.array(ner_targ) > -1)\n",
    "    ner_count_correct = np.count_nonzero((np.array(ner_pred)==np.array(ner_targ)) == True)\n",
    "\n",
    "    f1_score(sbd_pred, sbd_targ)\n",
    "    f1_score(sbd_middle_pred, sbd_middle_targ)\n",
    "    print(\"POS Accuracy:\"+ str(pos_count_correct/pos_count_active_tokens))\n",
    "    print(\"NER Accuracy:\"+ str(ner_count_correct/ner_count_active_tokens))\n",
    "\n",
    "    '''\n",
    "    print(\"sbd_targ: \",sbd_targ)\n",
    "    print(\"sbd_pred: \",sbd_pred)\n",
    "\n",
    "    print(\"pos_targ: \",pos_targ)\n",
    "    print(\"pos_pred: \",pos_pred)\n",
    "\n",
    "    print(\"ner_targ: \",ner_targ)\n",
    "    print(\"ner_pred: \",ner_pred)\n",
    "    '''\n",
    "    ner_f1_score(ner_pred, ner_targ)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    #count_active_tokens = np.count_nonzero(np.array(total_targ) > -1)\n",
    "    #count_correct = np.count_nonzero((np.array(total_pred)==np.array(total_targ)) == True)\n",
    "    #print(\"TESTING ACC:\", count_correct/count_active_tokens)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx in range(200):\n",
    "    train_loop_fn(train_loader, model, optimizer)\n",
    "    dev_loop_fn(test_loader, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_loop_fn(test_loader, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    \"state_dict\": model.state_dict(),\n",
    "    \"optimizer\": optimizer.state_dict(),\n",
    "    \"train_dataset\": train_dataset\n",
    "}\n",
    "save_checkpoint(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = torch.rand(2, 5, 7)\n",
    "pos = torch.rand(2, 5, 4)\n",
    "ner = torch.rand(2, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 7])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_tran = torch.nn.Linear(7, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = att_tran(bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1533,  0.1327,  0.0695],\n",
       "         [ 0.0054,  0.2945, -0.4304],\n",
       "         [ 0.3683,  0.1229,  0.1090],\n",
       "         [ 0.4943, -0.0547, -0.0932],\n",
       "         [ 0.2551,  0.1087, -0.0534]],\n",
       "\n",
       "        [[-0.2049,  0.1968, -0.1915],\n",
       "         [ 0.1369, -0.0428, -0.2880],\n",
       "         [-0.0694, -0.0399, -0.0412],\n",
       "         [ 0.1252, -0.1475, -0.0315],\n",
       "         [ 0.1277,  0.2669, -0.1522]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_weight = torch.softmax(transformed, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3449, 0.3379, 0.3172],\n",
       "         [0.3353, 0.4478, 0.2169],\n",
       "         [0.3916, 0.3063, 0.3021],\n",
       "         [0.4688, 0.2707, 0.2605],\n",
       "         [0.3848, 0.3324, 0.2827]],\n",
       "\n",
       "        [[0.2851, 0.4260, 0.2889],\n",
       "         [0.4017, 0.3356, 0.2627],\n",
       "         [0.3270, 0.3367, 0.3363],\n",
       "         [0.3822, 0.2910, 0.3268],\n",
       "         [0.3442, 0.3956, 0.2602]]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor to have size 3 at dimension 1, but got size 5 for argument #2 'batch2' (while checking arguments for bmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-a6247a6dd671>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matt_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#att_weight@bert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor to have size 3 at dimension 1, but got size 5 for argument #2 'batch2' (while checking arguments for bmm)"
     ]
    }
   ],
   "source": [
    "feature = torch.bmm(att_weight, bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor to have size 3 at dimension 1, but got size 5 for argument #2 'batch2' (while checking arguments for bmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-b0ad3a419fd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0matt_weight\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor to have size 3 at dimension 1, but got size 5 for argument #2 'batch2' (while checking arguments for bmm)"
     ]
    }
   ],
   "source": [
    "att_weight@bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.4 on Python 3.6 (CUDA 10.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
